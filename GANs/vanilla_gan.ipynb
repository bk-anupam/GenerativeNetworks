{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import wandb\n",
    "import imageio\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"./mnist_data\"\n",
    "class Config:\n",
    "    RUNTIME = \"KAGGLE\"\n",
    "    SUBSET_FRACTION = None\n",
    "    NUM_EPOCHS = 30\n",
    "    BATCH_SIZE = 64\n",
    "    PRECISION = \"16-mixed\"\n",
    "    LOG_EVERY_N_STEPS = 10\n",
    "    INPUT_IMAGE_SIZE = (45, 45)    \n",
    "    DIM_Z = 100\n",
    "    NUM_WORKERS = mp.cpu_count()\n",
    "    EARLY_STOPPING_PATIENCE = 6  # Add this line for early stopping patience\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Training on', Config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbConfig:\n",
    "    WANDB_KEY = \"\"\n",
    "    WANDB_RUN_NAME = \"vanilla_gan_testrun\"\n",
    "    WANDB_PROJECT = \"vanilla_gan\"\n",
    "    USE_WANDB = False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_secrets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Config\u001b[38;5;241m.\u001b[39mRUNTIME \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKAGGLE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkaggle_secrets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserSecretsClient\n\u001b[1;32m      3\u001b[0m     user_secrets \u001b[38;5;241m=\u001b[39m UserSecretsClient()\n\u001b[1;32m      4\u001b[0m     WANDB_KEY \u001b[38;5;241m=\u001b[39m user_secrets\u001b[38;5;241m.\u001b[39mget_secret(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_secrets'"
     ]
    }
   ],
   "source": [
    "if Config.RUNTIME == \"KAGGLE\":\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    WANDB_KEY = user_secrets.get_secret(\"wandb\")\n",
    "    DATASET_PATH = \"/kaggle/working/mnist_data\"\n",
    "\n",
    "if WandbConfig.USE_WANDB:\n",
    "    # Log in to W&B\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_KEY\n",
    "    # Initialize W&B\n",
    "    wandb.init(project=WandbConfig.WANDB_PROJECT, name=WandbConfig.WANDB_RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set transform to normalize data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# each row in mnist dataset is a tuple of (image, label)\n",
    "mnist_data = datasets.MNIST(root=DATASET_PATH, train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_data, \n",
    "                                          batch_size=Config.BATCH_SIZE, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./mnist_data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(nn.Module):\n",
    "    def __init__(self, dim_z):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        self.dim_z = dim_z\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: latent_dim x 1 x 1\n",
    "            nn.Linear(self.dim_z, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 28 * 28), # 28*28 = 784 (MNIST image size)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display input and output images\n",
    "def display_images(input_img, output_img, epoch):    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(4, 2))\n",
    "    axes[0].imshow(input_img)    \n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[1].imshow(output_img)    \n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitorCallback(Callback):\n",
    "    def __init__(self, model, validation_z, log_images=True):\n",
    "        self.model = model\n",
    "        self.validation_z = validation_z\n",
    "        self.log_images = log_images\n",
    "        self.epoch_g_loss = 0.0\n",
    "        self.epoch_d_loss = 0.0\n",
    "        self.epoch_batches = 0\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        self.epoch_g_loss += outputs[\"g_loss\"]\n",
    "        self.epoch_d_loss += outputs[\"d_loss\"]\n",
    "        self.epoch_batches += 1\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        avg_g_loss = self.epoch_g_loss / self.epoch_batches\n",
    "        avg_d_loss = self.epoch_d_loss / self.epoch_batches\n",
    "        print(f\"Epoch {trainer.current_epoch} - Generator Loss: {avg_g_loss:.4f}, Discriminator Loss: {avg_d_loss:.4f}\")\n",
    "        self.epoch_g_loss = 0.0\n",
    "        self.epoch_d_loss = 0.0\n",
    "        self.epoch_batches = 0\n",
    "        # Generate and plot images if enabled\n",
    "        if self.log_images:\n",
    "            self.visualize_images(trainer.current_epoch)\n",
    "\n",
    "    def visualize_images(self, epoch):\n",
    "        \"\"\"Generate and display images.\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            generated_imgs = self.model(self.validation_z.to(self.model.device))\n",
    "        self.model.train()\n",
    "\n",
    "        # Create figure\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'Generated Images (Epoch {epoch})')\n",
    "        img_grid = torchvision.utils.make_grid(generated_imgs.cpu(), normalize=True, nrow=8)\n",
    "        plt.imshow(img_grid.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistGAN(pl.LightningModule):\n",
    "    def __init__(self, dim_z, lr=0.0002, b1=0.5, b2=0.999):\n",
    "        super(MnistGAN, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # hyperparameters\n",
    "        self.dim_z = dim_z\n",
    "        self.lr = lr\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2        \n",
    "        # networks\n",
    "        self.discriminator = DiscriminatorNet()\n",
    "        self.generator = GeneratorNet(self.dim_z)\n",
    "        # losses\n",
    "        self.adversarial_loss = nn.BCEWithLogitsLoss()        \n",
    "        self.validation_z = torch.randn(4, self.dim_z)\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, _ = batch\n",
    "        # Get optimizers\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "        # train generator        \n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.dim_z, device=Config.DEVICE)\n",
    "        # clear gradients from previous step \n",
    "        opt_g.zero_grad()\n",
    "        # generate images (forward pass)\n",
    "        generated_imgs = self(z)\n",
    "        # In the training of the generator, the goal is to fool the discriminator into thinking that the generated images are real.\n",
    "        # This is why, when training the generator, the target labels (valid) are set to 1. The generator wants to make its generated\n",
    "        # images look as real as possible so that the discriminator will classify them as real.\n",
    "        # If you set the ground truth labels to 0, the generator would be trying to generate images that the discriminator\n",
    "        # can confidently classify as fake, which goes against the goal of training the generator. We want to train the generator\n",
    "        # to improve its ability to deceive the discriminator, not make it easier for the discriminator to identify fake images.\n",
    "        real = torch.ones(imgs.size(0), 1, device=Config.DEVICE)        \n",
    "        # adversarial loss is binary cross-entropy\n",
    "        g_loss = self.adversarial_loss(self.discriminator(generated_imgs), real)\n",
    "        # calculate gradients for generator \n",
    "        self.manual_backward(g_loss)\n",
    "        # update generator weights\n",
    "        opt_g.step()                \n",
    "        # train discriminator        \n",
    "        # ground truth result (ie: all fake)\n",
    "        real = torch.ones(imgs.size(0), 1, device=Config.DEVICE)\n",
    "        fake = torch.zeros(imgs.size(0), 1, device=Config.DEVICE)\n",
    "        opt_d.zero_grad()\n",
    "        # adversarial loss is binary cross-entropy\n",
    "        real_loss = self.adversarial_loss(self.discriminator(imgs), real)\n",
    "        fake_loss = self.adversarial_loss(self.discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        # calculate gradients for discriminator\n",
    "        self.manual_backward(d_loss)\n",
    "        # update discriminator weights\n",
    "        opt_d.step()\n",
    "        self.log('d_loss', d_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('g_loss', g_loss, prog_bar=True, on_epoch=True)\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.lr\n",
    "        b1 = self.b1\n",
    "        b2 = self.b2\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [opt_g, opt_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GAN model\n",
    "model = MnistGAN(Config.DIM_Z)\n",
    "wandb_logger = None\n",
    "if WandbConfig.USE_WANDB:\n",
    "    wandb_logger = WandbLogger(project=WandbConfig.WANDB_PROJECT, name=WandbConfig.WANDB_RUN_NAME)    \n",
    "\n",
    "# Generate fixed noise for validation\n",
    "validation_z = torch.randn(8, model.dim_z)\n",
    "gan_monitor = GANMonitorCallback(model=model, validation_z=validation_z, log_images=True)\n",
    "# Initialize Trainer with W&B logger\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=Config.NUM_EPOCHS,\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        logger=wandb_logger,\n",
    "        enable_model_summary=True,\n",
    "        precision=Config.PRECISION,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=Config.LOG_EVERY_N_STEPS,\n",
    "        callbacks=[gan_monitor]\n",
    "    )    \n",
    "trainer.fit(model, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "pythonundefinedundefinedundefinedjvsc74a57bd09235b876b2d02d86a4d23fd2f9f35be0402b4c2f3f24d9b1465a8b3785c74901"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
